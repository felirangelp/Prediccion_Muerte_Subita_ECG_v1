"""
Configuraci√≥n y optimizaci√≥n para MacBook Pro M1 (Apple Silicon)
Optimiza el uso de GPU Metal y recursos del sistema
"""

import os
import platform
import warnings
from typing import Optional

def check_m1_system() -> bool:
    """
    Verifica si el sistema es un Mac con Apple Silicon (M1/M2/M3)
    
    Returns:
        True si es Mac con Apple Silicon, False en caso contrario
    """
    return platform.system() == "Darwin" and platform.machine() == "arm64"

def configure_tensorflow_m1() -> dict:
    """
    Configura TensorFlow para usar GPU Metal en Mac M1
    
    Returns:
        Diccionario con informaci√≥n de configuraci√≥n
    """
    config = {
        'm1_detected': check_m1_system(),
        'tensorflow_backend': None,
        'gpu_available': False,
        'gpu_device': None
    }
    
    if not config['m1_detected']:
        warnings.warn("No se detect√≥ Mac M1. Las optimizaciones M1 no se aplicar√°n.")
        return config
    
    try:
        import tensorflow as tf
        
        # Configurar para usar Metal Performance Shaders
        if hasattr(tf.config, 'list_physical_devices'):
            devices = tf.config.list_physical_devices()
            gpu_devices = [d for d in devices if 'GPU' in d.name or 'Metal' in d.name]
            
            if gpu_devices:
                config['gpu_available'] = True
                config['gpu_device'] = gpu_devices[0].name
                
                # Configurar crecimiento de memoria para GPU
                try:
                    for gpu in gpu_devices:
                        tf.config.experimental.set_memory_growth(gpu, True)
                except:
                    pass
                
                # Configurar backend
                os.environ['TF_METAL_DEVICE_LIST'] = '0'
                config['tensorflow_backend'] = 'Metal (GPU)'
            else:
                config['tensorflow_backend'] = 'CPU'
        else:
            config['tensorflow_backend'] = 'CPU'
            
    except ImportError:
        warnings.warn("TensorFlow no est√° instalado. Instala tensorflow-macos y tensorflow-metal para M1.")
        config['tensorflow_backend'] = 'Not Available'
    
    return config

def optimize_numpy_scipy():
    """
    Configura optimizaciones para NumPy y SciPy en M1
    """
    # Configurar variables de entorno para optimizaci√≥n
    if check_m1_system():
        # Usar Accelerate framework de Apple
        os.environ['VECLIB_MAXIMUM_THREADS'] = '1'  # Evitar conflictos con MKL
        os.environ['OPENBLAS_NUM_THREADS'] = '1'
        
        try:
            import numpy as np
            # Verificar si NumPy est√° usando aceleraci√≥n
            if hasattr(np, '__config__'):
                print("‚úÖ NumPy configurado para M1")
        except:
            pass

def get_optimal_batch_size(model_type: str = 'default') -> int:
    """
    Obtiene el tama√±o de batch √≥ptimo para diferentes modelos en M1
    
    Args:
        model_type: Tipo de modelo ('sparse', 'hierarchical', 'hybrid', 'default')
    
    Returns:
        Tama√±o de batch recomendado
    """
    if not check_m1_system():
        # Valores conservadores para sistemas no-M1
        return {
            'sparse': 16,
            'hierarchical': 8,
            'hybrid': 4,
            'default': 16
        }.get(model_type, 16)
    
    # Valores optimizados para M1
    batch_sizes = {
        'sparse': 32,      # Representaciones dispersas son m√°s ligeras
        'hierarchical': 16,  # Fusi√≥n jer√°rquica requiere m√°s memoria
        'hybrid': 8,       # Modelo h√≠brido es m√°s complejo
        'default': 32
    }
    
    return batch_sizes.get(model_type, 32)

def setup_memory_management():
    """
    Configura gesti√≥n de memoria optimizada para M1
    """
    if check_m1_system():
        # Configurar l√≠mites de memoria si es necesario
        # M1 Pro/Max tienen m√°s memoria unificada
        import psutil
        
        total_memory_gb = psutil.virtual_memory().total / (1024**3)
        
        if total_memory_gb >= 32:
            # Mac con 32GB+ puede manejar m√°s datos en memoria
            os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'
        else:
            # Mac con 16GB o menos, ser m√°s conservador
            os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'
            os.environ['TF_METAL_DEVICE_LIST'] = '0'

def print_system_info():
    """
    Imprime informaci√≥n del sistema y configuraci√≥n
    """
    print("=" * 60)
    print("üîß Configuraci√≥n del Sistema - MacBook Pro M1")
    print("=" * 60)
    
    m1_detected = check_m1_system()
    print(f"‚úÖ Mac M1 detectado: {m1_detected}")
    
    if m1_detected:
        print(f"üì± Sistema: {platform.system()} {platform.machine()}")
        print(f"üêç Python: {platform.python_version()}")
        
        # Informaci√≥n de TensorFlow
        tf_config = configure_tensorflow_m1()
        print(f"\nü§ñ TensorFlow:")
        print(f"   Backend: {tf_config['tensorflow_backend']}")
        print(f"   GPU disponible: {tf_config['gpu_available']}")
        if tf_config['gpu_device']:
            print(f"   Dispositivo GPU: {tf_config['gpu_device']}")
        
        # Informaci√≥n de memoria
        try:
            import psutil
            memory = psutil.virtual_memory()
            print(f"\nüíæ Memoria:")
            print(f"   Total: {memory.total / (1024**3):.2f} GB")
            print(f"   Disponible: {memory.available / (1024**3):.2f} GB")
        except:
            pass
        
        # Batch sizes recomendados
        print(f"\nüìä Tama√±os de batch recomendados:")
        print(f"   Representaciones Dispersas: {get_optimal_batch_size('sparse')}")
        print(f"   Fusi√≥n Jer√°rquica: {get_optimal_batch_size('hierarchical')}")
        print(f"   Modelo H√≠brido: {get_optimal_batch_size('hybrid')}")
    
    print("=" * 60)

if __name__ == "__main__":
    # Ejecutar configuraci√≥n y mostrar informaci√≥n
    optimize_numpy_scipy()
    setup_memory_management()
    print_system_info()
